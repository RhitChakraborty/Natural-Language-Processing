{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product Sentiment Classification",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2cd9b4b787d47c583664bd550b5213e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e716765d497540f490139f0ccc85b0e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96913beaf1d942cc94739a1401a7caf4",
              "IPY_MODEL_eea7f3b75bd8471f944b103ffe8ca9d0"
            ]
          }
        },
        "e716765d497540f490139f0ccc85b0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96913beaf1d942cc94739a1401a7caf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3521549e276f4469a0b822823a006a56",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a4291c3f789414e8a16c84e6ad6b832"
          }
        },
        "eea7f3b75bd8471f944b103ffe8ca9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62a1759ed1744a97bfefcb3ed3be2199",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 143/143 [36:23&lt;00:00, 15.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a79749983ff4180a09a7606841d833b"
          }
        },
        "3521549e276f4469a0b822823a006a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a4291c3f789414e8a16c84e6ad6b832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62a1759ed1744a97bfefcb3ed3be2199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a79749983ff4180a09a7606841d833b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eb286d4ea744fcb92c91c038039e22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e183fc61989489ab7c1484a7f393477",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6484d3d0700d4911b9c92c8da4b1f6dd",
              "IPY_MODEL_b5b12a72932b4d14856bf9206c5f8581"
            ]
          }
        },
        "0e183fc61989489ab7c1484a7f393477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6484d3d0700d4911b9c92c8da4b1f6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f95045d7947544c38e4ed81296363933",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 72,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 72,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15f04a9e7f1d4750b94004d75cd7d6ad"
          }
        },
        "b5b12a72932b4d14856bf9206c5f8581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_734b226ba1cb4485a54c8cec74b716a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 72/72 [11:51&lt;00:00,  9.88s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c5923e54c7745ec9a7418d06745ba23"
          }
        },
        "f95045d7947544c38e4ed81296363933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15f04a9e7f1d4750b94004d75cd7d6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "734b226ba1cb4485a54c8cec74b716a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c5923e54c7745ec9a7418d06745ba23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ27JR8Wqjtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "61d8c082-0e4c-4b92-b156-7c8a26e105ae"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/86/c3dcb600b4f9e7584ed90ea9d30a717fb5c0111574675f442c3e7bc19535/catboost-0.24.1-cp36-none-manylinux1_x86_64.whl (66.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.1MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBNwM7ZVqveb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhXAm9GZrUhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"Train.csv\")\n",
        "test = pd.read_csv(\"Test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRq7aFQMrUe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_df=pd.concat([train,test],axis=0).reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdcOeTDfrZzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#full_df['Product_Description']=full_df['Product_Description'].apply(lambda x:re.sub(r\"\\W+\",' ',x))\n",
        "full_df['length']=full_df['Product_Description'].apply(lambda x:len(re.findall(r\"\\w+\",x)))\n",
        "m=full_df.groupby('Product_Type')['length'].agg(['mean','max','min'])\n",
        "full_df=full_df.merge(m,on='Product_Type',how='left')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGukHCEuraAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f9633a98-1c1c-445b-ded2-eefd2f15ed9c"
      },
      "source": [
        "full_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Product_Description</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>length</th>\n",
              "      <th>mean</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3057</td>\n",
              "      <td>The Web DesignerÂ‰Ã›Âªs Guide to iOS (and Android...</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6254</td>\n",
              "      <td>RT @mention Line for iPad 2 is longer today th...</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8212</td>\n",
              "      <td>Crazy that Apple is opening a temporary store ...</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4422</td>\n",
              "      <td>The lesson from Google One Pass: In this digit...</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5526</td>\n",
              "      <td>RT @mention At the panel: &amp;quot;Your mom has a...</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text_ID                                Product_Description  ...  max  min\n",
              "0     3057  The Web DesignerÂ‰Ã›Âªs Guide to iOS (and Android...  ...   41    2\n",
              "1     6254  RT @mention Line for iPad 2 is longer today th...  ...   41    2\n",
              "2     8212  Crazy that Apple is opening a temporary store ...  ...   41    2\n",
              "3     4422  The lesson from Google One Pass: In this digit...  ...   41    2\n",
              "4     5526  RT @mention At the panel: &quot;Your mom has a...  ...   41    2\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX8yzq4kraDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a37c3a4-0f54-413e-ffb9-0b3eb1c49ec2"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=ba85f24b1784f88f9c0519f972818ab559191f0d73b8fc5363359bf99af243da\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/74/49848e9bb64482a7e5f475cc66da5de759077817ede36f8812060ebcaba6/sentence-transformers-0.3.6.tar.gz (62kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.6-cp36-none-any.whl size=101182 sha256=767e8c05536e3ecf0ac60889c74f613a9cf9d537d15814995cd867ad38ab1a63\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/3f/75/c0c4b3ef5dfbf8806d37b8dc661861772aba2f7aa419c85a9b\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YsYqq7GraGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "347d7c4c-359b-4931-d1d1-773010cfea49"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tokenizers\n",
        "print('TF version',tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFoXPsXWWGPU",
        "colab_type": "text"
      },
      "source": [
        "# **Roberta Large Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1dgfGfaraJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c70c7dc-25f1-45ad-8316-e0c4bf5fa0f8"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentence_embedder = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.31G/1.31G [01:55<00:00, 11.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVc12qlutFxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "c2cd9b4b787d47c583664bd550b5213e",
            "e716765d497540f490139f0ccc85b0e4",
            "96913beaf1d942cc94739a1401a7caf4",
            "eea7f3b75bd8471f944b103ffe8ca9d0",
            "3521549e276f4469a0b822823a006a56",
            "4a4291c3f789414e8a16c84e6ad6b832",
            "62a1759ed1744a97bfefcb3ed3be2199",
            "4a79749983ff4180a09a7606841d833b"
          ]
        },
        "outputId": "0dc83b52-3400-4919-d235-5b12ef752f2d"
      },
      "source": [
        "%%time\n",
        "sentence_embeddings = sentence_embedder.encode(full_df.Product_Description.values.tolist(),batch_size=64,show_progress_bar=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2cd9b4b787d47c583664bd550b5213e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=143.0, style=ProgressStyle(description_widtâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 30.7 s, sys: 15.5 s, total: 46.2 s\n",
            "Wall time: 52.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lChiSGatu9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "62c22826-1d18-4044-b314-d6a74d7a23b4"
      },
      "source": [
        "data = pd.DataFrame(sentence_embeddings)\n",
        "for i in [\"Product_Type\",\"Sentiment\",\"length\",\"mean\",\"max\",\"min\"]:\n",
        "  data[i] = full_df[i].values\n",
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "      <th>1000</th>\n",
              "      <th>1001</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1004</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "      <th>1009</th>\n",
              "      <th>1010</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>length</th>\n",
              "      <th>mean</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.330165</td>\n",
              "      <td>-0.247397</td>\n",
              "      <td>-0.870642</td>\n",
              "      <td>0.005058</td>\n",
              "      <td>0.354620</td>\n",
              "      <td>-0.836421</td>\n",
              "      <td>1.249181</td>\n",
              "      <td>-0.627187</td>\n",
              "      <td>-0.034642</td>\n",
              "      <td>-0.239110</td>\n",
              "      <td>0.474412</td>\n",
              "      <td>-1.271331</td>\n",
              "      <td>-0.416535</td>\n",
              "      <td>0.245359</td>\n",
              "      <td>-0.990853</td>\n",
              "      <td>0.118077</td>\n",
              "      <td>-0.088616</td>\n",
              "      <td>0.332720</td>\n",
              "      <td>-0.189814</td>\n",
              "      <td>0.052836</td>\n",
              "      <td>-0.358442</td>\n",
              "      <td>-1.129598</td>\n",
              "      <td>-1.480089</td>\n",
              "      <td>0.960928</td>\n",
              "      <td>0.202038</td>\n",
              "      <td>1.771792</td>\n",
              "      <td>1.036318</td>\n",
              "      <td>-1.168895</td>\n",
              "      <td>-0.092231</td>\n",
              "      <td>-0.332392</td>\n",
              "      <td>-0.727229</td>\n",
              "      <td>1.432422</td>\n",
              "      <td>-0.914551</td>\n",
              "      <td>0.855940</td>\n",
              "      <td>-0.750450</td>\n",
              "      <td>-0.466039</td>\n",
              "      <td>0.084275</td>\n",
              "      <td>-1.321737</td>\n",
              "      <td>0.246428</td>\n",
              "      <td>-0.685505</td>\n",
              "      <td>...</td>\n",
              "      <td>0.743919</td>\n",
              "      <td>0.187946</td>\n",
              "      <td>0.056851</td>\n",
              "      <td>-0.372119</td>\n",
              "      <td>0.295995</td>\n",
              "      <td>-0.707240</td>\n",
              "      <td>-1.057208</td>\n",
              "      <td>-0.606955</td>\n",
              "      <td>0.074582</td>\n",
              "      <td>-0.230364</td>\n",
              "      <td>-0.240018</td>\n",
              "      <td>1.797071</td>\n",
              "      <td>-1.269070</td>\n",
              "      <td>-0.876562</td>\n",
              "      <td>-0.449873</td>\n",
              "      <td>-1.003565</td>\n",
              "      <td>-0.593831</td>\n",
              "      <td>-0.968504</td>\n",
              "      <td>1.194811</td>\n",
              "      <td>0.173917</td>\n",
              "      <td>-0.902885</td>\n",
              "      <td>-1.918223</td>\n",
              "      <td>-0.287934</td>\n",
              "      <td>0.338151</td>\n",
              "      <td>-1.320299</td>\n",
              "      <td>-1.120231</td>\n",
              "      <td>-0.587946</td>\n",
              "      <td>-0.453286</td>\n",
              "      <td>0.274506</td>\n",
              "      <td>0.553715</td>\n",
              "      <td>0.256694</td>\n",
              "      <td>-0.069876</td>\n",
              "      <td>-0.509241</td>\n",
              "      <td>-1.558362</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.278989</td>\n",
              "      <td>0.330941</td>\n",
              "      <td>-0.165491</td>\n",
              "      <td>-1.635586</td>\n",
              "      <td>0.687117</td>\n",
              "      <td>-0.535727</td>\n",
              "      <td>0.614250</td>\n",
              "      <td>1.429139</td>\n",
              "      <td>-0.475145</td>\n",
              "      <td>0.670293</td>\n",
              "      <td>-0.328978</td>\n",
              "      <td>0.634183</td>\n",
              "      <td>-0.217570</td>\n",
              "      <td>-0.002113</td>\n",
              "      <td>-0.577375</td>\n",
              "      <td>0.345339</td>\n",
              "      <td>0.807565</td>\n",
              "      <td>1.143098</td>\n",
              "      <td>1.049115</td>\n",
              "      <td>-0.005919</td>\n",
              "      <td>0.444396</td>\n",
              "      <td>-2.222993</td>\n",
              "      <td>0.773282</td>\n",
              "      <td>0.783117</td>\n",
              "      <td>0.237505</td>\n",
              "      <td>0.096515</td>\n",
              "      <td>-0.506388</td>\n",
              "      <td>-0.435858</td>\n",
              "      <td>0.655360</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>-1.252077</td>\n",
              "      <td>0.544314</td>\n",
              "      <td>-0.423391</td>\n",
              "      <td>-0.367903</td>\n",
              "      <td>-1.926222</td>\n",
              "      <td>0.767378</td>\n",
              "      <td>-2.255352</td>\n",
              "      <td>-0.418795</td>\n",
              "      <td>-0.075096</td>\n",
              "      <td>-0.679808</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.453680</td>\n",
              "      <td>-1.408923</td>\n",
              "      <td>0.569647</td>\n",
              "      <td>1.062356</td>\n",
              "      <td>-0.229778</td>\n",
              "      <td>0.375595</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>-0.098088</td>\n",
              "      <td>0.936759</td>\n",
              "      <td>0.275842</td>\n",
              "      <td>-0.804953</td>\n",
              "      <td>-0.857161</td>\n",
              "      <td>-2.376615</td>\n",
              "      <td>0.742030</td>\n",
              "      <td>0.466317</td>\n",
              "      <td>-1.231065</td>\n",
              "      <td>-1.222435</td>\n",
              "      <td>-0.363849</td>\n",
              "      <td>-0.511013</td>\n",
              "      <td>-0.013213</td>\n",
              "      <td>-0.533763</td>\n",
              "      <td>-2.542952</td>\n",
              "      <td>-0.107766</td>\n",
              "      <td>-0.374117</td>\n",
              "      <td>-0.254659</td>\n",
              "      <td>0.653225</td>\n",
              "      <td>0.864038</td>\n",
              "      <td>0.895205</td>\n",
              "      <td>1.169006</td>\n",
              "      <td>0.596770</td>\n",
              "      <td>0.461121</td>\n",
              "      <td>-0.165451</td>\n",
              "      <td>-0.091080</td>\n",
              "      <td>-0.331924</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.054071</td>\n",
              "      <td>0.683320</td>\n",
              "      <td>-0.719468</td>\n",
              "      <td>-0.993364</td>\n",
              "      <td>0.146501</td>\n",
              "      <td>-1.322316</td>\n",
              "      <td>0.569946</td>\n",
              "      <td>0.273334</td>\n",
              "      <td>0.294247</td>\n",
              "      <td>-0.616734</td>\n",
              "      <td>0.041258</td>\n",
              "      <td>-0.348921</td>\n",
              "      <td>0.146179</td>\n",
              "      <td>0.279477</td>\n",
              "      <td>-2.329789</td>\n",
              "      <td>0.841442</td>\n",
              "      <td>0.808261</td>\n",
              "      <td>0.518159</td>\n",
              "      <td>0.378362</td>\n",
              "      <td>-0.352653</td>\n",
              "      <td>0.894693</td>\n",
              "      <td>-0.749424</td>\n",
              "      <td>0.046378</td>\n",
              "      <td>0.433437</td>\n",
              "      <td>-0.055451</td>\n",
              "      <td>0.867230</td>\n",
              "      <td>-0.472142</td>\n",
              "      <td>0.023805</td>\n",
              "      <td>0.485383</td>\n",
              "      <td>0.047716</td>\n",
              "      <td>-0.218020</td>\n",
              "      <td>0.998918</td>\n",
              "      <td>-0.150348</td>\n",
              "      <td>-0.102221</td>\n",
              "      <td>-1.301127</td>\n",
              "      <td>-0.192057</td>\n",
              "      <td>-0.534871</td>\n",
              "      <td>-0.740003</td>\n",
              "      <td>0.566584</td>\n",
              "      <td>-1.096631</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.146204</td>\n",
              "      <td>0.086847</td>\n",
              "      <td>-0.393993</td>\n",
              "      <td>-0.126912</td>\n",
              "      <td>0.996776</td>\n",
              "      <td>-1.153902</td>\n",
              "      <td>-0.766382</td>\n",
              "      <td>-0.377434</td>\n",
              "      <td>0.723442</td>\n",
              "      <td>0.191847</td>\n",
              "      <td>-0.814166</td>\n",
              "      <td>-1.085052</td>\n",
              "      <td>-1.658119</td>\n",
              "      <td>-0.498427</td>\n",
              "      <td>-0.452110</td>\n",
              "      <td>-2.083881</td>\n",
              "      <td>-0.777529</td>\n",
              "      <td>-1.643397</td>\n",
              "      <td>0.891261</td>\n",
              "      <td>0.315838</td>\n",
              "      <td>-0.626215</td>\n",
              "      <td>-0.960399</td>\n",
              "      <td>-0.703349</td>\n",
              "      <td>-0.219069</td>\n",
              "      <td>-0.047881</td>\n",
              "      <td>-0.796186</td>\n",
              "      <td>0.478782</td>\n",
              "      <td>0.991951</td>\n",
              "      <td>0.238711</td>\n",
              "      <td>0.564170</td>\n",
              "      <td>0.152122</td>\n",
              "      <td>-0.402951</td>\n",
              "      <td>-1.189984</td>\n",
              "      <td>0.525129</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.283736</td>\n",
              "      <td>1.077794</td>\n",
              "      <td>0.115693</td>\n",
              "      <td>-0.754599</td>\n",
              "      <td>-0.353901</td>\n",
              "      <td>0.099093</td>\n",
              "      <td>0.026904</td>\n",
              "      <td>-1.588506</td>\n",
              "      <td>-0.343078</td>\n",
              "      <td>0.776587</td>\n",
              "      <td>0.609058</td>\n",
              "      <td>-1.232810</td>\n",
              "      <td>-0.395967</td>\n",
              "      <td>1.201138</td>\n",
              "      <td>0.514959</td>\n",
              "      <td>-1.009338</td>\n",
              "      <td>0.468748</td>\n",
              "      <td>-0.771186</td>\n",
              "      <td>0.470583</td>\n",
              "      <td>0.265297</td>\n",
              "      <td>-0.536604</td>\n",
              "      <td>-1.432280</td>\n",
              "      <td>-0.155619</td>\n",
              "      <td>-0.208997</td>\n",
              "      <td>0.023684</td>\n",
              "      <td>0.743148</td>\n",
              "      <td>-0.802505</td>\n",
              "      <td>-0.559221</td>\n",
              "      <td>-0.890675</td>\n",
              "      <td>-0.530240</td>\n",
              "      <td>-0.387051</td>\n",
              "      <td>0.228818</td>\n",
              "      <td>-0.881575</td>\n",
              "      <td>0.404648</td>\n",
              "      <td>-0.383866</td>\n",
              "      <td>0.167418</td>\n",
              "      <td>0.385697</td>\n",
              "      <td>-1.069829</td>\n",
              "      <td>-0.677940</td>\n",
              "      <td>-0.791103</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>0.424859</td>\n",
              "      <td>-0.052332</td>\n",
              "      <td>-0.475321</td>\n",
              "      <td>2.061460</td>\n",
              "      <td>-0.723258</td>\n",
              "      <td>-1.593484</td>\n",
              "      <td>0.001796</td>\n",
              "      <td>0.298123</td>\n",
              "      <td>0.493564</td>\n",
              "      <td>-0.735725</td>\n",
              "      <td>-1.200398</td>\n",
              "      <td>-0.975538</td>\n",
              "      <td>0.123734</td>\n",
              "      <td>-0.091106</td>\n",
              "      <td>-1.905183</td>\n",
              "      <td>-0.579613</td>\n",
              "      <td>-1.124421</td>\n",
              "      <td>1.478265</td>\n",
              "      <td>-0.436936</td>\n",
              "      <td>-0.394281</td>\n",
              "      <td>-1.356696</td>\n",
              "      <td>-1.036585</td>\n",
              "      <td>0.999023</td>\n",
              "      <td>-0.608468</td>\n",
              "      <td>-0.067053</td>\n",
              "      <td>-0.116878</td>\n",
              "      <td>0.798799</td>\n",
              "      <td>0.617623</td>\n",
              "      <td>0.398502</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>0.483582</td>\n",
              "      <td>-0.040487</td>\n",
              "      <td>-0.366792</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.685147</td>\n",
              "      <td>0.356008</td>\n",
              "      <td>-0.141168</td>\n",
              "      <td>-0.743663</td>\n",
              "      <td>-0.430732</td>\n",
              "      <td>-0.503180</td>\n",
              "      <td>-0.009455</td>\n",
              "      <td>-0.170719</td>\n",
              "      <td>-0.768279</td>\n",
              "      <td>0.383436</td>\n",
              "      <td>-0.045505</td>\n",
              "      <td>-0.437405</td>\n",
              "      <td>0.072291</td>\n",
              "      <td>-0.533039</td>\n",
              "      <td>0.044454</td>\n",
              "      <td>-1.127246</td>\n",
              "      <td>0.013488</td>\n",
              "      <td>0.391307</td>\n",
              "      <td>1.493541</td>\n",
              "      <td>1.116441</td>\n",
              "      <td>-0.713018</td>\n",
              "      <td>-0.380920</td>\n",
              "      <td>0.693903</td>\n",
              "      <td>0.676983</td>\n",
              "      <td>-0.356788</td>\n",
              "      <td>-0.496086</td>\n",
              "      <td>0.489434</td>\n",
              "      <td>-1.643811</td>\n",
              "      <td>-0.468427</td>\n",
              "      <td>-0.708996</td>\n",
              "      <td>-0.463611</td>\n",
              "      <td>1.014461</td>\n",
              "      <td>0.284167</td>\n",
              "      <td>0.857794</td>\n",
              "      <td>-0.694770</td>\n",
              "      <td>-2.135303</td>\n",
              "      <td>1.083803</td>\n",
              "      <td>-0.472779</td>\n",
              "      <td>-0.645185</td>\n",
              "      <td>-0.088481</td>\n",
              "      <td>...</td>\n",
              "      <td>0.458621</td>\n",
              "      <td>-1.409883</td>\n",
              "      <td>0.815893</td>\n",
              "      <td>-1.152876</td>\n",
              "      <td>0.937024</td>\n",
              "      <td>-0.232832</td>\n",
              "      <td>-0.673952</td>\n",
              "      <td>-1.275878</td>\n",
              "      <td>-0.651407</td>\n",
              "      <td>0.106804</td>\n",
              "      <td>0.852991</td>\n",
              "      <td>-0.961393</td>\n",
              "      <td>-2.609520</td>\n",
              "      <td>1.181577</td>\n",
              "      <td>-0.190355</td>\n",
              "      <td>-0.792485</td>\n",
              "      <td>0.025200</td>\n",
              "      <td>0.082749</td>\n",
              "      <td>0.371371</td>\n",
              "      <td>0.144736</td>\n",
              "      <td>-0.636164</td>\n",
              "      <td>-0.750758</td>\n",
              "      <td>0.167548</td>\n",
              "      <td>0.452039</td>\n",
              "      <td>-0.660471</td>\n",
              "      <td>0.731407</td>\n",
              "      <td>-0.638428</td>\n",
              "      <td>2.368103</td>\n",
              "      <td>0.084374</td>\n",
              "      <td>1.719391</td>\n",
              "      <td>-0.300217</td>\n",
              "      <td>-0.135863</td>\n",
              "      <td>-1.261115</td>\n",
              "      <td>0.310947</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16</td>\n",
              "      <td>18.126013</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1030 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...  length       mean  max  min\n",
              "0  0.330165 -0.247397 -0.870642  0.005058  ...      17  18.126013   41    2\n",
              "1  0.278989  0.330941 -0.165491 -1.635586  ...      22  18.126013   41    2\n",
              "2  0.054071  0.683320 -0.719468 -0.993364  ...      20  18.126013   41    2\n",
              "3 -1.283736  1.077794  0.115693 -0.754599  ...      22  18.126013   41    2\n",
              "4 -0.685147  0.356008 -0.141168 -0.743663  ...      16  18.126013   41    2\n",
              "\n",
              "[5 rows x 1030 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JioA1IdCtvJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[data.Sentiment.notna()]\n",
        "test = data[data.Sentiment.isna()]\n",
        "test.drop(\"Sentiment\",axis=1,inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofKCj6VFtvV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e05338f-b3f7-4243-b664-e0511116d37d"
      },
      "source": [
        "train.shape,test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6364, 1030), (2728, 1029))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHzS72jHJbVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train.drop([\"Sentiment\"],axis=1)\n",
        "y_train= train[['Sentiment']]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fF5p5ldPJGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgjonyl_L9SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce077139-e719-4151-f0c9-b3357058a3b4"
      },
      "source": [
        "params = {\n",
        "    \"od_type\":\"Iter\",\n",
        "    \"od_wait\":150,\n",
        "    \"iterations\":25000,\n",
        "    'learning_rate':0.0355,\n",
        "    \"eval_metric\":\"Accuracy\",\n",
        "    \"task_type\":\"GPU\",\n",
        "    \"boosting_type\":\"Plain\"\n",
        "}\n",
        "\n",
        "\n",
        "best_score = np.inf\n",
        "scores = []\n",
        "\n",
        "kf=KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "for train_idx , test_idx in kf.split(x_train,y_train):\n",
        "  train_set = (x_train.iloc[train_idx],y_train.iloc[train_idx])\n",
        "  test_set = (x_train.iloc[test_idx],y_train.iloc[test_idx])\n",
        "\n",
        "  model=CatBoostClassifier(**params)\n",
        "  model.fit(*train_set,\n",
        "            cat_features=['Product_Type'],\n",
        "            eval_set=[test_set],\n",
        "            early_stopping_rounds=500,\n",
        "            verbose=100)\n",
        "  score=log_loss(test_set[1].values,model.predict_proba(test_set[0]))\n",
        "\n",
        "  print(score)\n",
        "  scores.append(score)\n",
        "\n",
        "  if score<best_score:\n",
        "    best_Score=score\n",
        "    best_model=model\n",
        "\n",
        "  print('-'*100)\n",
        "\n",
        "print(f\"Mean Score : {np.array(scores).mean()}\")\n",
        "print(f\"Min Score : {np.array(scores).min()}\")\n",
        "print(f\"Max Score : {np.array(scores).max()}\")\n",
        "\n",
        "plt.plot(scores)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8764486\ttest: 0.8782404\tbest: 0.8782404 (0)\ttotal: 28.9ms\tremaining: 12m 3s\n",
            "100:\tlearn: 0.8970733\ttest: 0.8868814\tbest: 0.8884525 (67)\ttotal: 2.18s\tremaining: 8m 58s\n",
            "200:\tlearn: 0.9041446\ttest: 0.8908091\tbest: 0.8908091 (190)\ttotal: 4.24s\tremaining: 8m 43s\n",
            "300:\tlearn: 0.9070909\ttest: 0.8931658\tbest: 0.8931658 (288)\ttotal: 6.28s\tremaining: 8m 35s\n",
            "400:\tlearn: 0.9121980\ttest: 0.8931658\tbest: 0.8931658 (288)\ttotal: 8.3s\tremaining: 8m 28s\n",
            "500:\tlearn: 0.9155372\ttest: 0.8931658\tbest: 0.8931658 (288)\ttotal: 10.3s\tremaining: 8m 25s\n",
            "600:\tlearn: 0.9167158\ttest: 0.8931658\tbest: 0.8939513 (547)\ttotal: 12.3s\tremaining: 8m 19s\n",
            "700:\tlearn: 0.9198586\ttest: 0.8939513\tbest: 0.8939513 (547)\ttotal: 14.3s\tremaining: 8m 14s\n",
            "800:\tlearn: 0.9259478\ttest: 0.8947368\tbest: 0.8947368 (771)\ttotal: 16.2s\tremaining: 8m 10s\n",
            "900:\tlearn: 0.9292870\ttest: 0.8947368\tbest: 0.8947368 (771)\ttotal: 18.3s\tremaining: 8m 8s\n",
            "1000:\tlearn: 0.9353762\ttest: 0.8947368\tbest: 0.8947368 (771)\ttotal: 20.3s\tremaining: 8m 5s\n",
            "1100:\tlearn: 0.9416618\ttest: 0.8955224\tbest: 0.8955224 (1097)\ttotal: 22.2s\tremaining: 8m 1s\n",
            "1200:\tlearn: 0.9483402\ttest: 0.8955224\tbest: 0.8955224 (1097)\ttotal: 24.2s\tremaining: 7m 59s\n",
            "1300:\tlearn: 0.9536437\ttest: 0.8955224\tbest: 0.8955224 (1097)\ttotal: 26.1s\tremaining: 7m 56s\n",
            "1400:\tlearn: 0.9603221\ttest: 0.8963079\tbest: 0.8963079 (1382)\ttotal: 28.1s\tremaining: 7m 53s\n",
            "1500:\tlearn: 0.9652328\ttest: 0.8955224\tbest: 0.8963079 (1382)\ttotal: 30.1s\tremaining: 7m 51s\n",
            "1600:\tlearn: 0.9715184\ttest: 0.8955224\tbest: 0.8963079 (1382)\ttotal: 32s\tremaining: 7m 48s\n",
            "1700:\tlearn: 0.9774111\ttest: 0.8955224\tbest: 0.8963079 (1382)\ttotal: 33.9s\tremaining: 7m 44s\n",
            "1800:\tlearn: 0.9819289\ttest: 0.8947368\tbest: 0.8963079 (1382)\ttotal: 35.8s\tremaining: 7m 41s\n",
            "bestTest = 0.896307934\n",
            "bestIteration = 1382\n",
            "Shrink model to first 1383 iterations.\n",
            "0.38710639667626895\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0:\tlearn: 0.8723237\ttest: 0.8860958\tbest: 0.8860958 (0)\ttotal: 23.4ms\tremaining: 9m 44s\n",
            "100:\tlearn: 0.8955019\ttest: 0.9002357\tbest: 0.9010212 (18)\ttotal: 2.15s\tremaining: 8m 49s\n",
            "200:\tlearn: 0.9008053\ttest: 0.9041634\tbest: 0.9041634 (165)\ttotal: 4.11s\tremaining: 8m 26s\n",
            "300:\tlearn: 0.9063052\ttest: 0.9073056\tbest: 0.9073056 (298)\ttotal: 6.04s\tremaining: 8m 15s\n",
            "400:\tlearn: 0.9080731\ttest: 0.9065200\tbest: 0.9080911 (379)\ttotal: 8.01s\tremaining: 8m 11s\n",
            "500:\tlearn: 0.9106266\ttest: 0.9080911\tbest: 0.9088767 (477)\ttotal: 10s\tremaining: 8m 10s\n",
            "600:\tlearn: 0.9143587\ttest: 0.9080911\tbest: 0.9088767 (477)\ttotal: 12s\tremaining: 8m 5s\n",
            "700:\tlearn: 0.9182872\ttest: 0.9088767\tbest: 0.9096622 (684)\ttotal: 14s\tremaining: 8m 3s\n",
            "800:\tlearn: 0.9220192\ttest: 0.9088767\tbest: 0.9096622 (684)\ttotal: 15.9s\tremaining: 8m 1s\n",
            "900:\tlearn: 0.9269299\ttest: 0.9088767\tbest: 0.9096622 (684)\ttotal: 17.9s\tremaining: 7m 59s\n",
            "1000:\tlearn: 0.9314477\ttest: 0.9088767\tbest: 0.9096622 (684)\ttotal: 19.8s\tremaining: 7m 55s\n",
            "1100:\tlearn: 0.9369476\ttest: 0.9096622\tbest: 0.9096622 (684)\ttotal: 21.8s\tremaining: 7m 52s\n",
            "bestTest = 0.9096622152\n",
            "bestIteration = 684\n",
            "Shrink model to first 685 iterations.\n",
            "0.3311769581090693\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0:\tlearn: 0.8801807\ttest: 0.8656716\tbest: 0.8656716 (0)\ttotal: 23.7ms\tremaining: 9m 52s\n",
            "100:\tlearn: 0.9027696\ttest: 0.8695994\tbest: 0.8695994 (88)\ttotal: 2.14s\tremaining: 8m 46s\n",
            "200:\tlearn: 0.9065017\ttest: 0.8735271\tbest: 0.8743126 (197)\ttotal: 4.19s\tremaining: 8m 37s\n",
            "300:\tlearn: 0.9112159\ttest: 0.8743126\tbest: 0.8750982 (206)\ttotal: 6.18s\tremaining: 8m 26s\n",
            "400:\tlearn: 0.9141622\ttest: 0.8735271\tbest: 0.8750982 (206)\ttotal: 8.12s\tremaining: 8m 18s\n",
            "500:\tlearn: 0.9163229\ttest: 0.8758837\tbest: 0.8758837 (480)\ttotal: 10.1s\tremaining: 8m 13s\n",
            "600:\tlearn: 0.9188764\ttest: 0.8750982\tbest: 0.8766693 (591)\ttotal: 12.1s\tremaining: 8m 9s\n",
            "700:\tlearn: 0.9231978\ttest: 0.8758837\tbest: 0.8766693 (591)\ttotal: 14s\tremaining: 8m 6s\n",
            "800:\tlearn: 0.9261442\ttest: 0.8758837\tbest: 0.8766693 (591)\ttotal: 16s\tremaining: 8m 3s\n",
            "900:\tlearn: 0.9310548\ttest: 0.8758837\tbest: 0.8766693 (591)\ttotal: 18s\tremaining: 8m 1s\n",
            "1000:\tlearn: 0.9363583\ttest: 0.8750982\tbest: 0.8766693 (591)\ttotal: 20s\tremaining: 8m\n",
            "bestTest = 0.8766692852\n",
            "bestIteration = 591\n",
            "Shrink model to first 592 iterations.\n",
            "0.4235431310258075\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0:\tlearn: 0.8780200\ttest: 0.8688138\tbest: 0.8688138 (0)\ttotal: 24.8ms\tremaining: 10m 20s\n",
            "100:\tlearn: 0.8966804\ttest: 0.8798115\tbest: 0.8805970 (86)\ttotal: 2.19s\tremaining: 8m 59s\n",
            "200:\tlearn: 0.9029660\ttest: 0.8821681\tbest: 0.8821681 (192)\ttotal: 4.26s\tremaining: 8m 45s\n",
            "300:\tlearn: 0.9047338\ttest: 0.8845247\tbest: 0.8845247 (274)\ttotal: 6.29s\tremaining: 8m 36s\n",
            "400:\tlearn: 0.9092516\ttest: 0.8860958\tbest: 0.8868814 (393)\ttotal: 8.33s\tremaining: 8m 31s\n",
            "500:\tlearn: 0.9120016\ttest: 0.8860958\tbest: 0.8868814 (393)\ttotal: 10.3s\tremaining: 8m 22s\n",
            "600:\tlearn: 0.9143587\ttest: 0.8868814\tbest: 0.8876669 (552)\ttotal: 12.2s\tremaining: 8m 15s\n",
            "700:\tlearn: 0.9175015\ttest: 0.8876669\tbest: 0.8876669 (552)\ttotal: 14.2s\tremaining: 8m 11s\n",
            "800:\tlearn: 0.9214300\ttest: 0.8876669\tbest: 0.8876669 (552)\ttotal: 16.1s\tremaining: 8m 7s\n",
            "900:\tlearn: 0.9267335\ttest: 0.8876669\tbest: 0.8876669 (552)\ttotal: 18.1s\tremaining: 8m 3s\n",
            "1000:\tlearn: 0.9308584\ttest: 0.8884525\tbest: 0.8884525 (995)\ttotal: 20s\tremaining: 7m 59s\n",
            "1100:\tlearn: 0.9355726\ttest: 0.8884525\tbest: 0.8884525 (995)\ttotal: 21.9s\tremaining: 7m 55s\n",
            "1200:\tlearn: 0.9422510\ttest: 0.8892380\tbest: 0.8892380 (1190)\ttotal: 23.8s\tremaining: 7m 52s\n",
            "1300:\tlearn: 0.9495188\ttest: 0.8900236\tbest: 0.8900236 (1276)\ttotal: 25.7s\tremaining: 7m 48s\n",
            "1400:\tlearn: 0.9563936\ttest: 0.8900236\tbest: 0.8900236 (1276)\ttotal: 27.7s\tremaining: 7m 45s\n",
            "1500:\tlearn: 0.9622864\ttest: 0.8923802\tbest: 0.8923802 (1462)\ttotal: 29.6s\tremaining: 7m 43s\n",
            "1600:\tlearn: 0.9675899\ttest: 0.8923802\tbest: 0.8923802 (1462)\ttotal: 31.5s\tremaining: 7m 40s\n",
            "1700:\tlearn: 0.9705362\ttest: 0.8923802\tbest: 0.8931658 (1658)\ttotal: 33.5s\tremaining: 7m 38s\n",
            "1800:\tlearn: 0.9756433\ttest: 0.8939513\tbest: 0.8939513 (1779)\ttotal: 35.4s\tremaining: 7m 36s\n",
            "1900:\tlearn: 0.9787861\ttest: 0.8931658\tbest: 0.8939513 (1779)\ttotal: 37.4s\tremaining: 7m 34s\n",
            "2000:\tlearn: 0.9844824\ttest: 0.8931658\tbest: 0.8939513 (1779)\ttotal: 39.4s\tremaining: 7m 33s\n",
            "2100:\tlearn: 0.9880181\ttest: 0.8939513\tbest: 0.8947368 (2069)\ttotal: 41.5s\tremaining: 7m 31s\n",
            "2200:\tlearn: 0.9899823\ttest: 0.8947368\tbest: 0.8947368 (2069)\ttotal: 43.4s\tremaining: 7m 29s\n",
            "2300:\tlearn: 0.9913573\ttest: 0.8947368\tbest: 0.8947368 (2069)\ttotal: 45.4s\tremaining: 7m 28s\n",
            "2400:\tlearn: 0.9921430\ttest: 0.8939513\tbest: 0.8947368 (2069)\ttotal: 47.4s\tremaining: 7m 26s\n",
            "2500:\tlearn: 0.9946965\ttest: 0.8939513\tbest: 0.8947368 (2069)\ttotal: 49.5s\tremaining: 7m 24s\n",
            "2600:\tlearn: 0.9962679\ttest: 0.8955224\tbest: 0.8955224 (2524)\ttotal: 51.5s\tremaining: 7m 23s\n",
            "2700:\tlearn: 0.9970536\ttest: 0.8963079\tbest: 0.8963079 (2651)\ttotal: 53.6s\tremaining: 7m 22s\n",
            "2800:\tlearn: 0.9976429\ttest: 0.8963079\tbest: 0.8963079 (2651)\ttotal: 55.5s\tremaining: 7m 20s\n",
            "2900:\tlearn: 0.9986250\ttest: 0.8963079\tbest: 0.8963079 (2651)\ttotal: 57.5s\tremaining: 7m 17s\n",
            "3000:\tlearn: 0.9986250\ttest: 0.8963079\tbest: 0.8963079 (2651)\ttotal: 59.4s\tremaining: 7m 15s\n",
            "3100:\tlearn: 0.9990179\ttest: 0.8970935\tbest: 0.8970935 (3023)\ttotal: 1m 1s\tremaining: 7m 13s\n",
            "3200:\tlearn: 0.9992143\ttest: 0.8955224\tbest: 0.8970935 (3023)\ttotal: 1m 3s\tremaining: 7m 11s\n",
            "3300:\tlearn: 0.9994107\ttest: 0.8955224\tbest: 0.8970935 (3023)\ttotal: 1m 5s\tremaining: 7m 8s\n",
            "3400:\tlearn: 0.9996071\ttest: 0.8970935\tbest: 0.8970935 (3023)\ttotal: 1m 7s\tremaining: 7m 6s\n",
            "3500:\tlearn: 0.9998036\ttest: 0.8970935\tbest: 0.8970935 (3023)\ttotal: 1m 9s\tremaining: 7m 4s\n",
            "bestTest = 0.89709348\n",
            "bestIteration = 3023\n",
            "Shrink model to first 3024 iterations.\n",
            "0.3569036409999346\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0:\tlearn: 0.8764729\ttest: 0.8765723\tbest: 0.8765723 (0)\ttotal: 25.2ms\tremaining: 10m 29s\n",
            "100:\tlearn: 0.8976826\ttest: 0.8891509\tbest: 0.8899371 (90)\ttotal: 2.18s\tremaining: 8m 57s\n",
            "200:\tlearn: 0.9027887\ttest: 0.8883648\tbest: 0.8899371 (90)\ttotal: 4.17s\tremaining: 8m 34s\n",
            "300:\tlearn: 0.9071092\ttest: 0.8907233\tbest: 0.8907233 (296)\ttotal: 6.2s\tremaining: 8m 29s\n",
            "400:\tlearn: 0.9110369\ttest: 0.8930818\tbest: 0.8938679 (377)\ttotal: 8.23s\tremaining: 8m 24s\n",
            "500:\tlearn: 0.9149647\ttest: 0.8922956\tbest: 0.8938679 (377)\ttotal: 10.2s\tremaining: 8m 20s\n",
            "600:\tlearn: 0.9171249\ttest: 0.8930818\tbest: 0.8938679 (377)\ttotal: 12.3s\tremaining: 8m 17s\n",
            "700:\tlearn: 0.9198743\ttest: 0.8930818\tbest: 0.8938679 (377)\ttotal: 14.3s\tremaining: 8m 14s\n",
            "800:\tlearn: 0.9239984\ttest: 0.8930818\tbest: 0.8946541 (709)\ttotal: 16.2s\tremaining: 8m 8s\n",
            "900:\tlearn: 0.9281225\ttest: 0.8938679\tbest: 0.8946541 (709)\ttotal: 18.1s\tremaining: 8m 4s\n",
            "1000:\tlearn: 0.9314611\ttest: 0.8938679\tbest: 0.8946541 (709)\ttotal: 20.1s\tremaining: 8m 2s\n",
            "1100:\tlearn: 0.9371563\ttest: 0.8954403\tbest: 0.8962264 (1090)\ttotal: 22.1s\tremaining: 7m 59s\n",
            "1200:\tlearn: 0.9434407\ttest: 0.8954403\tbest: 0.8962264 (1090)\ttotal: 24.1s\tremaining: 7m 57s\n",
            "1300:\tlearn: 0.9497251\ttest: 0.8954403\tbest: 0.8962264 (1090)\ttotal: 26.1s\tremaining: 7m 55s\n",
            "1400:\tlearn: 0.9544383\ttest: 0.8946541\tbest: 0.8962264 (1090)\ttotal: 28.1s\tremaining: 7m 53s\n",
            "1500:\tlearn: 0.9593480\ttest: 0.8962264\tbest: 0.8962264 (1090)\ttotal: 30.1s\tremaining: 7m 51s\n",
            "bestTest = 0.8962264151\n",
            "bestIteration = 1090\n",
            "Shrink model to first 1091 iterations.\n",
            "0.36943722718980215\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mean Score : 0.3736334708001765\n",
            "Min Score : 0.3311769581090693\n",
            "Max Score : 0.4235431310258075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6ef2330a58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciRlKwrOUMZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "44c9b5a4-26d2-44ea-fc3d-0cf74f56aed4"
      },
      "source": [
        "model_large=best_model\n",
        "m = pd.DataFrame(list(zip(x_train.columns,model_large.feature_importances_))).sort_values(1,ascending=False)\n",
        "m"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>Product_Type</td>\n",
              "      <td>28.237267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>max</td>\n",
              "      <td>8.351636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>min</td>\n",
              "      <td>5.007601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>655</td>\n",
              "      <td>0.969325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>0.701289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>641</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>339</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>981</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>250</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>857</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1029 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0          1\n",
              "1024  Product_Type  28.237267\n",
              "1027           max   8.351636\n",
              "1028           min   5.007601\n",
              "655            655   0.969325\n",
              "84              84   0.701289\n",
              "...            ...        ...\n",
              "641            641   0.000000\n",
              "339            339   0.000000\n",
              "981            981   0.000000\n",
              "250            250   0.000000\n",
              "857            857   0.000000\n",
              "\n",
              "[1029 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h9HNU7LR6fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "93f5781f-b677-467b-8151-d18e8e4cd6da"
      },
      "source": [
        "submission = pd.DataFrame(model_large.predict_proba(test))\n",
        "submission.columns = [f'Class_{i}' for i in submission.columns]\n",
        "submission"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001758</td>\n",
              "      <td>0.017944</td>\n",
              "      <td>0.039057</td>\n",
              "      <td>0.941241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023661</td>\n",
              "      <td>0.021991</td>\n",
              "      <td>0.926221</td>\n",
              "      <td>0.028128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.010544</td>\n",
              "      <td>0.004370</td>\n",
              "      <td>0.953619</td>\n",
              "      <td>0.031467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000952</td>\n",
              "      <td>0.011650</td>\n",
              "      <td>0.005955</td>\n",
              "      <td>0.981443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008517</td>\n",
              "      <td>0.002452</td>\n",
              "      <td>0.961234</td>\n",
              "      <td>0.027797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>0.018568</td>\n",
              "      <td>0.022584</td>\n",
              "      <td>0.930020</td>\n",
              "      <td>0.028827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2724</th>\n",
              "      <td>0.009435</td>\n",
              "      <td>0.003331</td>\n",
              "      <td>0.943129</td>\n",
              "      <td>0.044105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2725</th>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.023081</td>\n",
              "      <td>0.032327</td>\n",
              "      <td>0.942823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>0.011527</td>\n",
              "      <td>0.004554</td>\n",
              "      <td>0.956848</td>\n",
              "      <td>0.027072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>0.025187</td>\n",
              "      <td>0.242808</td>\n",
              "      <td>0.050765</td>\n",
              "      <td>0.681240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2728 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Class_0   Class_1   Class_2   Class_3\n",
              "0     0.001758  0.017944  0.039057  0.941241\n",
              "1     0.023661  0.021991  0.926221  0.028128\n",
              "2     0.010544  0.004370  0.953619  0.031467\n",
              "3     0.000952  0.011650  0.005955  0.981443\n",
              "4     0.008517  0.002452  0.961234  0.027797\n",
              "...        ...       ...       ...       ...\n",
              "2723  0.018568  0.022584  0.930020  0.028827\n",
              "2724  0.009435  0.003331  0.943129  0.044105\n",
              "2725  0.001770  0.023081  0.032327  0.942823\n",
              "2726  0.011527  0.004554  0.956848  0.027072\n",
              "2727  0.025187  0.242808  0.050765  0.681240\n",
              "\n",
              "[2728 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIJxpb80V1T9",
        "colab_type": "text"
      },
      "source": [
        "# **Roberta Base Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_BTT_SnVnX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63bd2d9c-0699-42e6-b142-49c09b5e938b"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "base_embedder=SentenceTransformer('roberta-base-nli-stsb-mean-tokens')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459M/459M [00:41<00:00, 10.9MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Kx2UaUWhDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "6eb286d4ea744fcb92c91c038039e22e",
            "0e183fc61989489ab7c1484a7f393477",
            "6484d3d0700d4911b9c92c8da4b1f6dd",
            "b5b12a72932b4d14856bf9206c5f8581",
            "f95045d7947544c38e4ed81296363933",
            "15f04a9e7f1d4750b94004d75cd7d6ad",
            "734b226ba1cb4485a54c8cec74b716a6",
            "3c5923e54c7745ec9a7418d06745ba23"
          ]
        },
        "outputId": "6225afda-1b1c-4f1b-f53f-b4736ff4d6ea"
      },
      "source": [
        "%%time\n",
        "base_embeddings = base_embedder.encode(full_df.Product_Description.values.tolist(),batch_size=128,show_progress_bar=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6eb286d4ea744fcb92c91c038039e22e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=72.0, style=ProgressStyle(description_widthâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 10.1 s, sys: 3.4 s, total: 13.5 s\n",
            "Wall time: 13.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nhsInpZXJoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "cc040f24-16ca-461c-80bc-db8f13a81e35"
      },
      "source": [
        "data = pd.DataFrame(base_embeddings)\n",
        "data['product'] = full_df.Product_Type.values\n",
        "data['Sentiment'] = full_df.Sentiment.values\n",
        "data.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>product</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.213892</td>\n",
              "      <td>-0.078237</td>\n",
              "      <td>0.425070</td>\n",
              "      <td>0.070156</td>\n",
              "      <td>-1.074826</td>\n",
              "      <td>0.550598</td>\n",
              "      <td>-0.037865</td>\n",
              "      <td>-0.941952</td>\n",
              "      <td>-0.268316</td>\n",
              "      <td>-0.193891</td>\n",
              "      <td>-0.715721</td>\n",
              "      <td>-0.916273</td>\n",
              "      <td>0.349077</td>\n",
              "      <td>2.603539</td>\n",
              "      <td>-0.809141</td>\n",
              "      <td>-0.517888</td>\n",
              "      <td>-0.613942</td>\n",
              "      <td>-0.071862</td>\n",
              "      <td>0.649604</td>\n",
              "      <td>0.367172</td>\n",
              "      <td>-0.763611</td>\n",
              "      <td>-0.734709</td>\n",
              "      <td>-1.457823</td>\n",
              "      <td>0.942833</td>\n",
              "      <td>0.230982</td>\n",
              "      <td>-0.227856</td>\n",
              "      <td>0.006733</td>\n",
              "      <td>-0.620646</td>\n",
              "      <td>-0.292909</td>\n",
              "      <td>0.870090</td>\n",
              "      <td>0.007132</td>\n",
              "      <td>0.351150</td>\n",
              "      <td>-0.023495</td>\n",
              "      <td>-1.252404</td>\n",
              "      <td>0.010694</td>\n",
              "      <td>0.275839</td>\n",
              "      <td>1.444032</td>\n",
              "      <td>0.154453</td>\n",
              "      <td>-0.187872</td>\n",
              "      <td>0.398615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868395</td>\n",
              "      <td>-0.326264</td>\n",
              "      <td>-0.124642</td>\n",
              "      <td>-1.243666</td>\n",
              "      <td>0.085748</td>\n",
              "      <td>1.448836</td>\n",
              "      <td>-0.943065</td>\n",
              "      <td>-0.522150</td>\n",
              "      <td>-0.666419</td>\n",
              "      <td>1.125074</td>\n",
              "      <td>-0.179955</td>\n",
              "      <td>-0.775389</td>\n",
              "      <td>0.708535</td>\n",
              "      <td>0.009818</td>\n",
              "      <td>0.076141</td>\n",
              "      <td>-0.168705</td>\n",
              "      <td>-1.096211</td>\n",
              "      <td>0.979141</td>\n",
              "      <td>-1.188685</td>\n",
              "      <td>0.732397</td>\n",
              "      <td>3.028975</td>\n",
              "      <td>0.011725</td>\n",
              "      <td>-0.001381</td>\n",
              "      <td>0.729547</td>\n",
              "      <td>-0.601280</td>\n",
              "      <td>-0.275464</td>\n",
              "      <td>0.252104</td>\n",
              "      <td>-0.515478</td>\n",
              "      <td>-0.310147</td>\n",
              "      <td>-1.296503</td>\n",
              "      <td>-0.788538</td>\n",
              "      <td>0.141525</td>\n",
              "      <td>0.052002</td>\n",
              "      <td>-0.038399</td>\n",
              "      <td>-0.338132</td>\n",
              "      <td>-0.666649</td>\n",
              "      <td>-0.774718</td>\n",
              "      <td>0.726099</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.346898</td>\n",
              "      <td>0.472381</td>\n",
              "      <td>0.174338</td>\n",
              "      <td>0.382898</td>\n",
              "      <td>0.700836</td>\n",
              "      <td>-0.872197</td>\n",
              "      <td>0.105461</td>\n",
              "      <td>-1.294667</td>\n",
              "      <td>0.211178</td>\n",
              "      <td>-0.362303</td>\n",
              "      <td>-0.059532</td>\n",
              "      <td>-0.872606</td>\n",
              "      <td>-0.133363</td>\n",
              "      <td>1.566071</td>\n",
              "      <td>-0.156924</td>\n",
              "      <td>-0.149481</td>\n",
              "      <td>1.586048</td>\n",
              "      <td>0.302141</td>\n",
              "      <td>0.831896</td>\n",
              "      <td>0.184373</td>\n",
              "      <td>-0.863887</td>\n",
              "      <td>-0.985159</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.304479</td>\n",
              "      <td>0.733572</td>\n",
              "      <td>-0.502838</td>\n",
              "      <td>1.414683</td>\n",
              "      <td>0.092136</td>\n",
              "      <td>-0.135937</td>\n",
              "      <td>-0.444432</td>\n",
              "      <td>-0.992245</td>\n",
              "      <td>-0.723863</td>\n",
              "      <td>0.307738</td>\n",
              "      <td>-0.396365</td>\n",
              "      <td>1.258619</td>\n",
              "      <td>0.617504</td>\n",
              "      <td>0.197209</td>\n",
              "      <td>-0.808149</td>\n",
              "      <td>-0.201551</td>\n",
              "      <td>0.492024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331355</td>\n",
              "      <td>-0.292540</td>\n",
              "      <td>-0.058145</td>\n",
              "      <td>1.397170</td>\n",
              "      <td>-0.057945</td>\n",
              "      <td>0.159776</td>\n",
              "      <td>0.698492</td>\n",
              "      <td>-0.977789</td>\n",
              "      <td>0.124115</td>\n",
              "      <td>1.854668</td>\n",
              "      <td>0.560097</td>\n",
              "      <td>0.068177</td>\n",
              "      <td>0.567218</td>\n",
              "      <td>-0.161923</td>\n",
              "      <td>0.272069</td>\n",
              "      <td>0.703144</td>\n",
              "      <td>-1.147982</td>\n",
              "      <td>0.189706</td>\n",
              "      <td>-0.526908</td>\n",
              "      <td>0.583283</td>\n",
              "      <td>0.246789</td>\n",
              "      <td>-0.592045</td>\n",
              "      <td>-1.132094</td>\n",
              "      <td>-1.183341</td>\n",
              "      <td>0.059489</td>\n",
              "      <td>-0.124017</td>\n",
              "      <td>-0.234554</td>\n",
              "      <td>0.381858</td>\n",
              "      <td>-0.445966</td>\n",
              "      <td>-0.121626</td>\n",
              "      <td>0.382501</td>\n",
              "      <td>-0.253044</td>\n",
              "      <td>-0.061907</td>\n",
              "      <td>-0.280201</td>\n",
              "      <td>1.683886</td>\n",
              "      <td>0.369114</td>\n",
              "      <td>-0.061391</td>\n",
              "      <td>-0.071466</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.248373</td>\n",
              "      <td>-0.218984</td>\n",
              "      <td>-0.784727</td>\n",
              "      <td>-0.593703</td>\n",
              "      <td>1.147771</td>\n",
              "      <td>0.023220</td>\n",
              "      <td>0.095660</td>\n",
              "      <td>-0.953652</td>\n",
              "      <td>1.356774</td>\n",
              "      <td>-0.427181</td>\n",
              "      <td>-0.530057</td>\n",
              "      <td>-0.766577</td>\n",
              "      <td>0.545995</td>\n",
              "      <td>0.167235</td>\n",
              "      <td>-0.324807</td>\n",
              "      <td>-0.668764</td>\n",
              "      <td>-0.207121</td>\n",
              "      <td>-0.418613</td>\n",
              "      <td>0.311894</td>\n",
              "      <td>0.082976</td>\n",
              "      <td>-0.942546</td>\n",
              "      <td>0.326792</td>\n",
              "      <td>-0.123100</td>\n",
              "      <td>1.035103</td>\n",
              "      <td>0.442710</td>\n",
              "      <td>0.321313</td>\n",
              "      <td>0.260160</td>\n",
              "      <td>0.161752</td>\n",
              "      <td>-0.653465</td>\n",
              "      <td>1.138607</td>\n",
              "      <td>-0.334309</td>\n",
              "      <td>-0.101767</td>\n",
              "      <td>0.381815</td>\n",
              "      <td>0.111047</td>\n",
              "      <td>-0.066624</td>\n",
              "      <td>1.274009</td>\n",
              "      <td>0.387226</td>\n",
              "      <td>0.030630</td>\n",
              "      <td>0.660716</td>\n",
              "      <td>0.925087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325310</td>\n",
              "      <td>-0.361140</td>\n",
              "      <td>0.315071</td>\n",
              "      <td>-0.062286</td>\n",
              "      <td>-0.351337</td>\n",
              "      <td>0.217063</td>\n",
              "      <td>-0.919611</td>\n",
              "      <td>-0.416872</td>\n",
              "      <td>-0.206933</td>\n",
              "      <td>0.725790</td>\n",
              "      <td>-0.272594</td>\n",
              "      <td>-0.156146</td>\n",
              "      <td>0.928170</td>\n",
              "      <td>1.190146</td>\n",
              "      <td>0.525851</td>\n",
              "      <td>-0.167361</td>\n",
              "      <td>-0.710153</td>\n",
              "      <td>0.788995</td>\n",
              "      <td>-1.088127</td>\n",
              "      <td>0.545342</td>\n",
              "      <td>1.018182</td>\n",
              "      <td>0.055635</td>\n",
              "      <td>-1.130887</td>\n",
              "      <td>-0.019745</td>\n",
              "      <td>0.754386</td>\n",
              "      <td>-0.353049</td>\n",
              "      <td>-0.670045</td>\n",
              "      <td>0.891854</td>\n",
              "      <td>-0.557709</td>\n",
              "      <td>-0.177769</td>\n",
              "      <td>-1.028671</td>\n",
              "      <td>-0.342752</td>\n",
              "      <td>-0.799658</td>\n",
              "      <td>0.052375</td>\n",
              "      <td>-0.883921</td>\n",
              "      <td>-0.313137</td>\n",
              "      <td>-0.394876</td>\n",
              "      <td>0.741146</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.204622</td>\n",
              "      <td>-0.484248</td>\n",
              "      <td>-0.732613</td>\n",
              "      <td>0.275955</td>\n",
              "      <td>0.471216</td>\n",
              "      <td>0.073464</td>\n",
              "      <td>0.497067</td>\n",
              "      <td>-0.904280</td>\n",
              "      <td>-1.605588</td>\n",
              "      <td>-0.668993</td>\n",
              "      <td>0.835571</td>\n",
              "      <td>-0.660802</td>\n",
              "      <td>0.076707</td>\n",
              "      <td>1.915384</td>\n",
              "      <td>0.351461</td>\n",
              "      <td>-0.662171</td>\n",
              "      <td>0.680130</td>\n",
              "      <td>-1.029940</td>\n",
              "      <td>0.284060</td>\n",
              "      <td>-0.761201</td>\n",
              "      <td>-0.663737</td>\n",
              "      <td>-1.056454</td>\n",
              "      <td>-0.343305</td>\n",
              "      <td>0.574852</td>\n",
              "      <td>0.764906</td>\n",
              "      <td>-0.247112</td>\n",
              "      <td>0.409612</td>\n",
              "      <td>0.430698</td>\n",
              "      <td>-1.319610</td>\n",
              "      <td>0.436424</td>\n",
              "      <td>-0.234470</td>\n",
              "      <td>0.419509</td>\n",
              "      <td>0.121122</td>\n",
              "      <td>-0.401447</td>\n",
              "      <td>-0.716404</td>\n",
              "      <td>-1.051662</td>\n",
              "      <td>0.530521</td>\n",
              "      <td>0.337925</td>\n",
              "      <td>-1.012575</td>\n",
              "      <td>-0.064081</td>\n",
              "      <td>...</td>\n",
              "      <td>0.076826</td>\n",
              "      <td>-0.635222</td>\n",
              "      <td>-0.556684</td>\n",
              "      <td>-0.228782</td>\n",
              "      <td>-0.278833</td>\n",
              "      <td>0.887008</td>\n",
              "      <td>-0.332633</td>\n",
              "      <td>-0.767181</td>\n",
              "      <td>0.344229</td>\n",
              "      <td>0.854491</td>\n",
              "      <td>1.427893</td>\n",
              "      <td>-0.567932</td>\n",
              "      <td>0.493857</td>\n",
              "      <td>-0.442764</td>\n",
              "      <td>0.487025</td>\n",
              "      <td>0.250618</td>\n",
              "      <td>-0.310737</td>\n",
              "      <td>1.045620</td>\n",
              "      <td>0.383705</td>\n",
              "      <td>0.190903</td>\n",
              "      <td>0.817358</td>\n",
              "      <td>-0.621836</td>\n",
              "      <td>-1.769947</td>\n",
              "      <td>-0.745835</td>\n",
              "      <td>-0.638201</td>\n",
              "      <td>0.393690</td>\n",
              "      <td>0.297211</td>\n",
              "      <td>0.084746</td>\n",
              "      <td>-0.735881</td>\n",
              "      <td>-0.543803</td>\n",
              "      <td>-1.393753</td>\n",
              "      <td>-1.021259</td>\n",
              "      <td>0.801923</td>\n",
              "      <td>-0.419521</td>\n",
              "      <td>0.898906</td>\n",
              "      <td>-0.391649</td>\n",
              "      <td>0.088145</td>\n",
              "      <td>0.047161</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.041500</td>\n",
              "      <td>0.722249</td>\n",
              "      <td>0.075889</td>\n",
              "      <td>0.485219</td>\n",
              "      <td>0.052400</td>\n",
              "      <td>-0.000332</td>\n",
              "      <td>0.575877</td>\n",
              "      <td>-0.414607</td>\n",
              "      <td>1.207509</td>\n",
              "      <td>-0.053550</td>\n",
              "      <td>-0.150645</td>\n",
              "      <td>0.876222</td>\n",
              "      <td>-0.437834</td>\n",
              "      <td>1.793088</td>\n",
              "      <td>0.008184</td>\n",
              "      <td>-0.156189</td>\n",
              "      <td>-0.854153</td>\n",
              "      <td>-0.404376</td>\n",
              "      <td>0.952931</td>\n",
              "      <td>1.199941</td>\n",
              "      <td>-0.733765</td>\n",
              "      <td>0.695882</td>\n",
              "      <td>0.126194</td>\n",
              "      <td>0.091031</td>\n",
              "      <td>1.174717</td>\n",
              "      <td>-0.076281</td>\n",
              "      <td>0.488973</td>\n",
              "      <td>-0.461732</td>\n",
              "      <td>-0.204822</td>\n",
              "      <td>-0.520778</td>\n",
              "      <td>-0.139238</td>\n",
              "      <td>0.479902</td>\n",
              "      <td>-0.803968</td>\n",
              "      <td>-0.378927</td>\n",
              "      <td>1.979360</td>\n",
              "      <td>-0.052741</td>\n",
              "      <td>-0.020153</td>\n",
              "      <td>0.455714</td>\n",
              "      <td>0.718170</td>\n",
              "      <td>0.010564</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993645</td>\n",
              "      <td>0.523447</td>\n",
              "      <td>-0.659796</td>\n",
              "      <td>-0.436317</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>0.815863</td>\n",
              "      <td>-0.058773</td>\n",
              "      <td>-0.983259</td>\n",
              "      <td>-0.923401</td>\n",
              "      <td>-0.111848</td>\n",
              "      <td>-0.288736</td>\n",
              "      <td>-0.057237</td>\n",
              "      <td>0.978343</td>\n",
              "      <td>0.805278</td>\n",
              "      <td>0.265515</td>\n",
              "      <td>0.485828</td>\n",
              "      <td>-0.681779</td>\n",
              "      <td>0.123267</td>\n",
              "      <td>-0.469056</td>\n",
              "      <td>0.682397</td>\n",
              "      <td>1.624950</td>\n",
              "      <td>0.500522</td>\n",
              "      <td>0.006723</td>\n",
              "      <td>-0.470188</td>\n",
              "      <td>0.145614</td>\n",
              "      <td>0.019362</td>\n",
              "      <td>1.157898</td>\n",
              "      <td>0.022074</td>\n",
              "      <td>-1.031456</td>\n",
              "      <td>-0.652306</td>\n",
              "      <td>0.118690</td>\n",
              "      <td>1.250861</td>\n",
              "      <td>0.643751</td>\n",
              "      <td>0.165139</td>\n",
              "      <td>1.584227</td>\n",
              "      <td>0.424470</td>\n",
              "      <td>-1.077421</td>\n",
              "      <td>0.588641</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 770 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       767  product  Sentiment\n",
              "0 -0.213892 -0.078237  0.425070  ...  0.726099        9        2.0\n",
              "1  0.346898  0.472381  0.174338  ... -0.071466        9        2.0\n",
              "2 -0.248373 -0.218984 -0.784727  ...  0.741146        9        2.0\n",
              "3 -0.204622 -0.484248 -0.732613  ...  0.047161        9        2.0\n",
              "4  0.041500  0.722249  0.075889  ...  0.588641        9        2.0\n",
              "\n",
              "[5 rows x 770 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRlJmuxkYCiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[data.Sentiment.notna()]\n",
        "test = data[data.Sentiment.isna()]\n",
        "test.drop(\"Sentiment\",axis=1,inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4UB1p-pYN1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ceb2a44e-add4-4c55-aeea-d53cc20d207c"
      },
      "source": [
        "x_train = train.drop([\"Sentiment\"],axis=1)\n",
        "y_train = train[['Sentiment']]\n",
        "\n",
        "params = {\n",
        "    \"od_type\":\"Iter\",\n",
        "    \"od_wait\":150,\n",
        "    \"iterations\":25000,\n",
        "    'learning_rate':0.0355,\n",
        "    \"eval_metric\":\"Accuracy\",\n",
        "    \"task_type\":\"GPU\",\n",
        "    # \"boosting_type\":\"Plain\"\n",
        "}\n",
        "\n",
        "best_score = np.inf\n",
        "scores = []\n",
        "\n",
        "kf = KFold(n_splits=5,shuffle=True,random_state=1250)\n",
        "\n",
        "for train_idx , test_idx in kf.split(x_train,y_train):\n",
        "  train_set = (x_train.iloc[train_idx],y_train.iloc[train_idx])\n",
        "  test_set = (x_train.iloc[test_idx],y_train.iloc[test_idx])\n",
        "\n",
        "  model = CatBoostClassifier(**params)\n",
        "  model.fit(*train_set,\n",
        "            cat_features = ['product'],\n",
        "            eval_set=[test_set],early_stopping_rounds=500,verbose=200)\n",
        "\n",
        "  score = log_loss(test_set[1].values,model.predict_proba(test_set[0]))\n",
        "  print(score)\n",
        "  scores.append(score)\n",
        "  \n",
        "\n",
        "  if score < best_score:\n",
        "    best_score = score\n",
        "    best_model = model\n",
        "\n",
        "  print(\"-\"*150)\n",
        "\n",
        "print(f\"Mean Score : {np.array(scores).mean()}\")\n",
        "print(f\"Min Score : {np.array(scores).min()}\")\n",
        "print(f\"Max Score : {np.array(scores).max()}\")\n",
        "\n",
        "plt.plot(scores)\n",
        "plt.show()\n",
        "\n",
        "model_base = best_model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 12035.875 Total: 16280.875\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8752701\ttest: 0.8750982\tbest: 0.8750982 (0)\ttotal: 23.8ms\tremaining: 9m 54s\n",
            "200:\tlearn: 0.9029660\ttest: 0.8860958\tbest: 0.8868814 (79)\ttotal: 3.82s\tremaining: 7m 51s\n",
            "400:\tlearn: 0.9096445\ttest: 0.8876669\tbest: 0.8876669 (230)\ttotal: 7.51s\tremaining: 7m 40s\n",
            "600:\tlearn: 0.9161265\ttest: 0.8892380\tbest: 0.8892380 (420)\ttotal: 11.2s\tremaining: 7m 34s\n",
            "800:\tlearn: 0.9237871\ttest: 0.8892380\tbest: 0.8892380 (420)\ttotal: 14.7s\tremaining: 7m 25s\n",
            "1000:\tlearn: 0.9341976\ttest: 0.8900236\tbest: 0.8908091 (932)\ttotal: 18.3s\tremaining: 7m 19s\n",
            "1200:\tlearn: 0.9442153\ttest: 0.8908091\tbest: 0.8908091 (932)\ttotal: 21.9s\tremaining: 7m 14s\n",
            "1400:\tlearn: 0.9569829\ttest: 0.8908091\tbest: 0.8915947 (1295)\ttotal: 25.4s\tremaining: 7m 7s\n",
            "1600:\tlearn: 0.9671970\ttest: 0.8908091\tbest: 0.8915947 (1295)\ttotal: 28.9s\tremaining: 7m 2s\n",
            "1800:\tlearn: 0.9752504\ttest: 0.8915947\tbest: 0.8923802 (1717)\ttotal: 32.4s\tremaining: 6m 57s\n",
            "2000:\tlearn: 0.9829110\ttest: 0.8915947\tbest: 0.8923802 (1717)\ttotal: 35.9s\tremaining: 6m 53s\n",
            "2200:\tlearn: 0.9897859\ttest: 0.8908091\tbest: 0.8923802 (1717)\ttotal: 39.5s\tremaining: 6m 49s\n",
            "bestTest = 0.8923802042\n",
            "bestIteration = 1717\n",
            "Shrink model to first 1718 iterations.\n",
            "0.3966944492298179\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 12035.875 Total: 16280.875\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8760558\ttest: 0.8750982\tbest: 0.8750982 (0)\ttotal: 24.4ms\tremaining: 10m 9s\n",
            "200:\tlearn: 0.9015910\ttest: 0.8876669\tbest: 0.8908091 (17)\ttotal: 3.81s\tremaining: 7m 49s\n",
            "400:\tlearn: 0.9104302\ttest: 0.8923802\tbest: 0.8923802 (353)\ttotal: 7.45s\tremaining: 7m 36s\n",
            "600:\tlearn: 0.9167158\ttest: 0.8915947\tbest: 0.8931658 (431)\ttotal: 11.1s\tremaining: 7m 32s\n",
            "800:\tlearn: 0.9230014\ttest: 0.8931658\tbest: 0.8939513 (783)\ttotal: 14.8s\tremaining: 7m 27s\n",
            "1000:\tlearn: 0.9334119\ttest: 0.8955224\tbest: 0.8955224 (891)\ttotal: 18.3s\tremaining: 7m 19s\n",
            "1200:\tlearn: 0.9442153\ttest: 0.8939513\tbest: 0.8955224 (891)\ttotal: 21.9s\tremaining: 7m 13s\n",
            "bestTest = 0.8955223881\n",
            "bestIteration = 891\n",
            "Shrink model to first 892 iterations.\n",
            "0.36744283321348725\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 12035.875 Total: 16280.875\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8784129\ttest: 0.8711705\tbest: 0.8711705 (0)\ttotal: 22.8ms\tremaining: 9m 30s\n",
            "200:\tlearn: 0.9039481\ttest: 0.8798115\tbest: 0.8805970 (185)\ttotal: 3.71s\tremaining: 7m 37s\n",
            "400:\tlearn: 0.9112159\ttest: 0.8813826\tbest: 0.8821681 (277)\ttotal: 7.28s\tremaining: 7m 26s\n",
            "600:\tlearn: 0.9173050\ttest: 0.8837392\tbest: 0.8837392 (577)\ttotal: 10.8s\tremaining: 7m 17s\n",
            "800:\tlearn: 0.9239835\ttest: 0.8853103\tbest: 0.8853103 (753)\ttotal: 14.4s\tremaining: 7m 15s\n",
            "1000:\tlearn: 0.9343940\ttest: 0.8860958\tbest: 0.8868814 (842)\ttotal: 18s\tremaining: 7m 12s\n",
            "1200:\tlearn: 0.9424475\ttest: 0.8860958\tbest: 0.8876669 (1049)\ttotal: 21.7s\tremaining: 7m 10s\n",
            "1400:\tlearn: 0.9548222\ttest: 0.8868814\tbest: 0.8876669 (1049)\ttotal: 25.4s\tremaining: 7m 7s\n",
            "bestTest = 0.8876669285\n",
            "bestIteration = 1049\n",
            "Shrink model to first 1050 iterations.\n",
            "0.3978791139576718\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 12035.875 Total: 16280.875\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8801807\ttest: 0.8554595\tbest: 0.8554595 (0)\ttotal: 22.1ms\tremaining: 9m 11s\n",
            "200:\tlearn: 0.9037517\ttest: 0.8735271\tbest: 0.8743126 (128)\ttotal: 3.73s\tremaining: 7m 40s\n",
            "400:\tlearn: 0.9094480\ttest: 0.8782404\tbest: 0.8790259 (387)\ttotal: 7.25s\tremaining: 7m 24s\n",
            "600:\tlearn: 0.9159301\ttest: 0.8790259\tbest: 0.8790259 (387)\ttotal: 10.8s\tremaining: 7m 19s\n",
            "800:\tlearn: 0.9249656\ttest: 0.8821681\tbest: 0.8821681 (800)\ttotal: 14.3s\tremaining: 7m 12s\n",
            "1000:\tlearn: 0.9330191\ttest: 0.8813826\tbest: 0.8821681 (800)\ttotal: 18s\tremaining: 7m 12s\n",
            "1200:\tlearn: 0.9459831\ttest: 0.8845247\tbest: 0.8845247 (1190)\ttotal: 21.7s\tremaining: 7m 9s\n",
            "1400:\tlearn: 0.9573758\ttest: 0.8853103\tbest: 0.8853103 (1210)\ttotal: 25.2s\tremaining: 7m 4s\n",
            "1600:\tlearn: 0.9671970\ttest: 0.8845247\tbest: 0.8853103 (1210)\ttotal: 28.9s\tremaining: 7m 2s\n",
            "bestTest = 0.8853102907\n",
            "bestIteration = 1210\n",
            "Shrink model to first 1211 iterations.\n",
            "0.3996959901313547\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 12035.875 Total: 16280.875\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.8701885\ttest: 0.8970126\tbest: 0.8970126 (0)\ttotal: 22.5ms\tremaining: 9m 23s\n",
            "200:\tlearn: 0.8986646\ttest: 0.9119497\tbest: 0.9119497 (166)\ttotal: 3.69s\tremaining: 7m 35s\n",
            "400:\tlearn: 0.9045562\ttest: 0.9135220\tbest: 0.9135220 (292)\ttotal: 7.25s\tremaining: 7m 25s\n",
            "600:\tlearn: 0.9114297\ttest: 0.9135220\tbest: 0.9135220 (292)\ttotal: 10.8s\tremaining: 7m 19s\n",
            "800:\tlearn: 0.9198743\ttest: 0.9150943\tbest: 0.9150943 (705)\ttotal: 14.5s\tremaining: 7m 17s\n",
            "1000:\tlearn: 0.9293009\ttest: 0.9150943\tbest: 0.9150943 (705)\ttotal: 18.1s\tremaining: 7m 15s\n",
            "1200:\tlearn: 0.9406913\ttest: 0.9166667\tbest: 0.9174528 (1115)\ttotal: 21.7s\tremaining: 7m 9s\n",
            "1400:\tlearn: 0.9522781\ttest: 0.9150943\tbest: 0.9174528 (1115)\ttotal: 25.2s\tremaining: 7m 4s\n",
            "1600:\tlearn: 0.9617046\ttest: 0.9150943\tbest: 0.9174528 (1115)\ttotal: 28.7s\tremaining: 6m 59s\n",
            "bestTest = 0.9174528302\n",
            "bestIteration = 1115\n",
            "Shrink model to first 1116 iterations.\n",
            "0.31326440827810664\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Mean Score : 0.37499535896208763\n",
            "Min Score : 0.31326440827810664\n",
            "Max Score : 0.3996959901313547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGt_WYHa1l4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e90e6655-b38a-4171-9315-fd5ace63631d"
      },
      "source": [
        "submission_base = pd.DataFrame(model_base.predict_proba(test))\n",
        "submission_base.columns = [f'Class_{i}' for i in submission_base.columns]\n",
        "submission_base"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002744</td>\n",
              "      <td>0.050912</td>\n",
              "      <td>0.031902</td>\n",
              "      <td>0.914443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.014622</td>\n",
              "      <td>0.027844</td>\n",
              "      <td>0.931766</td>\n",
              "      <td>0.025768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013976</td>\n",
              "      <td>0.010337</td>\n",
              "      <td>0.925876</td>\n",
              "      <td>0.049811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001267</td>\n",
              "      <td>0.010223</td>\n",
              "      <td>0.005660</td>\n",
              "      <td>0.982850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008717</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.974155</td>\n",
              "      <td>0.014666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>0.026310</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.914884</td>\n",
              "      <td>0.046038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2724</th>\n",
              "      <td>0.010783</td>\n",
              "      <td>0.004201</td>\n",
              "      <td>0.947652</td>\n",
              "      <td>0.037364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2725</th>\n",
              "      <td>0.000682</td>\n",
              "      <td>0.006713</td>\n",
              "      <td>0.023365</td>\n",
              "      <td>0.969240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>0.958203</td>\n",
              "      <td>0.031659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>0.028424</td>\n",
              "      <td>0.291076</td>\n",
              "      <td>0.055129</td>\n",
              "      <td>0.625371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2728 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Class_0   Class_1   Class_2   Class_3\n",
              "0     0.002744  0.050912  0.031902  0.914443\n",
              "1     0.014622  0.027844  0.931766  0.025768\n",
              "2     0.013976  0.010337  0.925876  0.049811\n",
              "3     0.001267  0.010223  0.005660  0.982850\n",
              "4     0.008717  0.002462  0.974155  0.014666\n",
              "...        ...       ...       ...       ...\n",
              "2723  0.026310  0.012768  0.914884  0.046038\n",
              "2724  0.010783  0.004201  0.947652  0.037364\n",
              "2725  0.000682  0.006713  0.023365  0.969240\n",
              "2726  0.007149  0.002989  0.958203  0.031659\n",
              "2727  0.028424  0.291076  0.055129  0.625371\n",
              "\n",
              "[2728 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDJDuWCFbNBr",
        "colab_type": "text"
      },
      "source": [
        "## Ensembling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzmCFjDVbJC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bd1db2f4-afa9-4b14-e597-89afa1016fa8"
      },
      "source": [
        "final_pred=(submission+submission_base)/2\n",
        "final_pred"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002251</td>\n",
              "      <td>0.034428</td>\n",
              "      <td>0.035479</td>\n",
              "      <td>0.927842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.019141</td>\n",
              "      <td>0.024917</td>\n",
              "      <td>0.928993</td>\n",
              "      <td>0.026948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.012260</td>\n",
              "      <td>0.007354</td>\n",
              "      <td>0.939747</td>\n",
              "      <td>0.040639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.010936</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.982146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008617</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0.967695</td>\n",
              "      <td>0.021231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>0.022439</td>\n",
              "      <td>0.017676</td>\n",
              "      <td>0.922452</td>\n",
              "      <td>0.037433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2724</th>\n",
              "      <td>0.010109</td>\n",
              "      <td>0.003766</td>\n",
              "      <td>0.945391</td>\n",
              "      <td>0.040734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2725</th>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.014897</td>\n",
              "      <td>0.027846</td>\n",
              "      <td>0.956031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>0.009338</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.957525</td>\n",
              "      <td>0.029366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.266942</td>\n",
              "      <td>0.052947</td>\n",
              "      <td>0.653306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2728 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Class_0   Class_1   Class_2   Class_3\n",
              "0     0.002251  0.034428  0.035479  0.927842\n",
              "1     0.019141  0.024917  0.928993  0.026948\n",
              "2     0.012260  0.007354  0.939747  0.040639\n",
              "3     0.001110  0.010936  0.005808  0.982146\n",
              "4     0.008617  0.002457  0.967695  0.021231\n",
              "...        ...       ...       ...       ...\n",
              "2723  0.022439  0.017676  0.922452  0.037433\n",
              "2724  0.010109  0.003766  0.945391  0.040734\n",
              "2725  0.001226  0.014897  0.027846  0.956031\n",
              "2726  0.009338  0.003771  0.957525  0.029366\n",
              "2727  0.026805  0.266942  0.052947  0.653306\n",
              "\n",
              "[2728 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1im30ogbYx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}